---
applyTo: '**'
---

# Project Rules

This document defines mandatory rules that all contributors and automation tools MUST follow when creating, generating, or modifying files in this repository. These rules ensure code quality, consistency, and maintainability across the project.

---

## Rule 1 — Mandatory Usage of the Nest CLI for Generated Files

Any file that corresponds to a Nest CLI schematic MUST be generated using the Nest CLI from the terminal. Examples of schematics include: application, class, controller, decorator, filter, gateway, guard, interceptor, interface, library, middleware, module, pipe, provider, resolver, resource, service, sub-app, and others listed by `nest --help`.

### Why this rule exists

- The Nest CLI generates files with correct decorators, imports and structure, reducing manual errors and keeping code consistent across the project.
- Ensures proper integration with NestJS dependency injection and module system.
- Maintains standardized file naming and organization conventions.

### How to apply (examples)

From the repository root (PowerShell on Windows):

```powershell
nest generate controller users    # or: nest g co users
nest generate service users       # or: nest g s users
nest generate module users        # or: nest g mo users
nest generate resource users      # or: nest g res users
```

### Enforcement and exceptions

- ✅ **REQUIRED**: Use Nest CLI for all controller, service, module, guard, interceptor, pipe, filter, middleware, and gateway files.
- ❌ **NEVER**: Create manually (copy/paste/new file) a file that matches any Nest schematic without running the CLI first.
- ✅ **ALLOWED**: Edit generated files after creation to add custom logic.
- ✅ **EXCEPTIONS**: Configuration files, documentation, assets, SQL files, build scripts, or other files not present in the Nest schematics list may be created manually.

### Code review and CI

- Code reviewers and CI should check whether schematic-like files were generated by the Nest CLI when possible.
- If a schematic-like file was created manually, the PR author MUST justify the reason in the PR description.

### Notes

- Short aliases (e.g., `g`, `co`, `s`, `mo`) are supported by the Nest CLI — use them for faster workflow.
- It is fine to edit generated files after creation, but generation must not be skipped.

---

## Rule 2 — Error Correction and Validation

Whenever an error is identified in the codebase, it MUST be corrected and validated before providing feedback about the correction. This ensures that the issue is fully resolved and prevents unnecessary iterations.

### Why this rule exists

- To maintain high code quality and reliability.
- To reduce the time spent on rework and ensure that fixes are effective.
- To build trust in the development process by ensuring that reported fixes are verified.
- To prevent cascading errors and broken builds.

### How to apply

1. **Identify the error** in the codebase (e.g., test failure, linting issue, runtime error).
2. **Implement the necessary fix** in the code.
3. **Validate the fix** by:
   - Running the relevant tests to ensure they pass: `pnpm test`
   - Verifying that the issue no longer occurs in the application.
   - Checking for any side effects introduced by the fix.
   - Running linting: `pnpm run lint`
   - Running formatting: `pnpm run format`
4. **Provide feedback** about the correction only after the validation is complete.

### Enforcement and exceptions

- ✅ **REQUIRED**: Feedback about a correction MUST include evidence of validation (e.g., test results, logs).
- ❌ **NEVER**: Report a fix as complete without validating it.
- ✅ **EXCEPTIONS**: None. All identified errors must follow this process.

### Code review and CI

- Code reviewers and CI should verify that fixes are validated before merging.
- Automated tools should be configured to block unvalidated fixes from being merged.

---

## Rule 3 — Formatting Corrections

To ensure consistent code formatting across the project, contributors and automation tools MUST run the formatting command to fix formatting issues before committing changes.

### Why this rule exists

- To maintain a consistent code style throughout the project.
- To reduce unnecessary diffs caused by formatting inconsistencies.
- To ensure that all contributors adhere to the same formatting standards.
- To prevent merge conflicts caused by formatting differences.

### How to apply

Before committing any changes, run the following command from the repository root:

```powershell
pnpm format
```

Verify that no formatting issues remain by checking the output of the command.

### Enforcement and exceptions

- ✅ **REQUIRED**: Run `pnpm format` before every commit.
- ✅ **AUTOMATED**: Husky + lint-staged automatically format files on commit.
- ❌ **NEVER**: Commit code with formatting issues.
- ✅ **EXCEPTIONS**: None. All changes must follow this rule.

### Code review and CI

- Automated tools block commits or merges if formatting issues are detected.
- Pre-commit hooks enforce formatting automatically.

---

## Rule 4 — Language Standardization and Context-Aware Communication

All **files, code, documentation, and written artifacts** MUST be written in **technical English** by default, while **interactive communication** (chat, discussions) may use the natural language preferred by the team.

### Why this rule exists

- **File Consistency**: Ensures all project artifacts are accessible to international developers and maintain long-term readability.
- **Global Collaboration**: Facilitates collaboration with international teams, open-source communities, and external contributors.
- **AI Integration**: Improves AI coding assistant comprehension, suggestions, and code analysis across all tools.
- **Documentation Longevity**: Makes project documentation and codebase accessible to a wider audience of developers over time.
- **Professional Standards**: Maintains industry-standard practices for software development documentation.
- **Communication Flexibility**: Allows natural language communication for better team collaboration and understanding.

### How to apply

#### Files and Written Artifacts (MUST use Technical English)

- ✅ **REQUIRED**: Use **technical English** for ALL files:
  - **Source Code**: Variable names, function names, class names, interfaces
  - **Code Comments**: Inline documentation, JSDoc comments, TODO notes
  - **Documentation**: README files, API docs, architecture guides, setup instructions
  - **Configuration**: Environment variables, config file comments, Docker files
  - **Database**: Table names, column names, migration comments, schema documentation
  - **Tests**: Test descriptions, test case names, assertion messages
  - **Commit Messages**: Following Conventional Commits specification
  - **Error Messages**: Application logs, error responses, validation messages
  - **Build Scripts**: Package.json scripts, CI/CD configurations, deployment notes
  - **Project Files**: Issue templates, PR templates, GitHub workflows

#### Interactive Communication (MAY use Natural Language)

- ✅ **ALLOWED**: Use **natural language** (Portuguese, etc.) for:
  - **Chat Messages**: Direct communication between team members
  - **Code Review Comments**: Feedback and discussions in PRs
  - **Issue Discussions**: Comments and discussions on GitHub issues
  - **Meeting Notes**: Internal team communication and planning
  - **Slack/Discord**: Real-time team communication
  - **Video Calls**: Verbal communication during development sessions

### Language Standards for Files

#### Technical English Requirements

- ✅ **CONSISTENT**: Use consistent technical terminology across the entire project
- ✅ **CLEAR**: Prefer clear, descriptive names over abbreviated or cryptic terms
- ✅ **STANDARD**: Follow industry-standard naming conventions and terminology
- ✅ **PRECISE**: Use precise technical language appropriate for software development
- ❌ **AVOID**: Colloquialisms, slang, or region-specific terminology in files

#### Examples

**✅ Correct File Content (Technical English)**

```typescript
// Service for handling user authentication and authorization
export class AuthService {
  /**
   * Validates user credentials and generates JWT token
   * @param credentials User login information
   * @returns Authentication result with token
   */
  async authenticateUser(credentials: LoginCredentials): Promise<AuthResult> {
    // Validate input parameters
    if (!credentials.email || !credentials.password) {
      throw new BadRequestException('Email and password are required');
    }
    // Implementation continues...
  }
}
```

**❌ Incorrect File Content (Mixed Language)**

```typescript
// Serviço para autenticação de usuários
export class AuthService {
  /**
   * Valida credenciais do usuário e gera token JWT
   */
  async autenticarUsuario(credenciais: any): Promise<any> {
    // Validar parâmetros de entrada
    throw new BadRequestException('Email e senha são obrigatórios');
  }
}
```

### Communication Context Examples

#### ✅ Allowed Chat Communication (Portuguese)

```
Chat: "Olá! Estou implementando a autenticação JWT.
Você pode revisar o código no AuthService?
Tenho dúvidas sobre a validação de tokens."
```

#### ✅ Required File Content (Technical English)

```markdown
# Authentication Module

This module implements JWT-based authentication with refresh tokens.

## Features

- User login with email/password
- JWT token generation and validation
- Refresh token rotation
- Role-based access control
```

### Enforcement and exceptions

#### Mandatory for Files

- ✅ **REQUIRED**: ALL project files must use technical English regardless of team's natural language
- ❌ **NEVER**: Mix languages in the same file or context
- ❌ **NEVER**: Use non-English terms in variable names, function names, or class names
- ✅ **AUTOMATED**: Linting rules should enforce English naming conventions where possible

#### Exceptions for Files

- ✅ **LOCALIZATION**: i18n/localization files may contain non-English text for user-facing content
- ✅ **EXPLICIT REQUEST**: Files may use other languages only when explicitly requested by project stakeholders for specific business requirements
- ✅ **EXTERNAL CONTENT**: Third-party documentation or quoted external content may retain original language

#### Communication Flexibility

- ✅ **TEAM CHOICE**: Teams may use their preferred natural language for verbal/chat communication
- ✅ **CONTEXT SWITCHING**: Developers can switch between Portuguese (chat) and English (files) as needed
- ✅ **INCLUSIVE**: Supports multilingual teams while maintaining consistent file standards

---

## Rule 5 — Code Quality and Readability

All code MUST follow clean code principles and maintain high readability standards.

### Why this rule exists

- Improves maintainability and reduces technical debt.
- Makes code easier to understand, debug, and extend.
- Reduces onboarding time for new developers.
- Prevents bugs and facilitates code reviews.

### How to apply

#### Clean Code Principles

- ✅ **SOLID**: Follow Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, Dependency Inversion.
- ✅ **DRY**: Don't Repeat Yourself - extract reusable logic into functions/services.
- ✅ **KISS**: Keep It Simple, Stupid - prefer simple solutions over complex ones.
- ✅ **Separation of Concerns**: Controllers handle HTTP, Services handle business logic, Repositories handle data access.

#### Naming Conventions

- ✅ **REQUIRED**: Use meaningful, descriptive, and consistent names.
  - Variables: `camelCase` (e.g., `userData`, `isAuthenticated`)
  - Functions/Methods: `camelCase` (e.g., `getUserById`, `validateToken`)
  - Classes/Interfaces: `PascalCase` (e.g., `UserService`, `AuthGuard`)
  - Constants: `UPPER_SNAKE_CASE` (e.g., `MAX_RETRIES`, `API_VERSION`)
  - Files: `kebab-case` (e.g., `user.service.ts`, `auth.guard.ts`)

#### Function/Module Design

- ✅ **REQUIRED**: Keep functions small, cohesive, and focused on a single responsibility.
- ✅ **REQUIRED**: Functions should do one thing and do it well.
- ❌ **AVOID**: Functions longer than 50 lines (consider refactoring).
- ❌ **AVOID**: Functions with more than 3-4 parameters (consider using objects).

#### Code Clarity

- ✅ **REQUIRED**: Prefer explicitness over clever tricks; clarity is more important than brevity.
- ❌ **AVOID**: Magic numbers and hard-coded values; use constants or configuration files.
- ❌ **AVOID**: Deep nesting (max 3 levels); extract to functions if needed.

### Enforcement and exceptions

- Code reviews should reject code that violates these principles.
- ESLint and TypeScript compiler enforce many of these rules automatically.

---

## Rule 6 — Documentation Standards and Controlled Generation

All features, modules, and architectural decisions MUST be documented through controlled processes. Documentation generation is restricted to specific prompt-based triggers to prevent unauthorized changes and maintain quality standards.

### Why this rule exists

- Ensures knowledge is preserved and accessible to all team members.
- Reduces dependency on individual developers.
- Facilitates onboarding and knowledge transfer.
- Improves code maintainability and debugging.
- **Prevents unauthorized documentation changes** that could introduce inconsistencies.
- **Maintains documentation quality** through controlled generation processes.
- **Ensures consistency** with actual implementation through systematic reviews.

### How to apply

#### Controlled Documentation Generation

- ✅ **REQUIRED**: Documentation generation MUST be triggered through specific prompts:
  - Use `wiki` reference for comprehensive project documentation
  - Use `readme` reference for executive summary generation
- ❌ **NEVER**: Generate, update, or modify documentation without explicit prompt triggers
- ❌ **NEVER**: Edit README.md or wiki files during regular chat interactions
- ✅ **ALLOWED**: Suggest documentation updates but never implement them automatically

#### Project Documentation Structure

- ✅ **REQUIRED**: Keep `README.md` up-to-date through controlled `readme` prompt
- ✅ **REQUIRED**: Organize detailed documentation in `docs/wiki/` through `wiki` prompt
- ✅ **REQUIRED**: Maintain topic-based wiki files for comprehensive coverage
- ✅ **REQUIRED**: Ensure documentation reflects current implementation state

#### Code Comments and Inline Documentation

- ✅ **REQUIRED**: Write comments only when the intent of code is not obvious.
- ✅ **FOCUS**: Comments should explain **why**, not **what**.
- ❌ **AVOID**: Obvious comments like `// increment i` for `i++`.
- ✅ **REQUIRED**: Document complex algorithms, business rules, and non-obvious decisions.

#### Documentation Quality Standards

- ✅ **REQUIRED**: Use technical English for all documentation (Rule 4 compliance)
- ✅ **REQUIRED**: Include practical, working code examples
- ✅ **REQUIRED**: Provide clear setup and usage instructions
- ✅ **REQUIRED**: Cross-reference between related documentation topics
- ✅ **REQUIRED**: Validate all examples and instructions for accuracy

### Enforcement and exceptions

#### Documentation Generation Control

- ✅ **REQUIRED**: All documentation changes must be explicitly requested with prompt triggers
- ❌ **NEVER**: Modify documentation files during regular development discussions
- ✅ **SUGGESTION**: Recommend documentation updates but do not implement them
- ✅ **VALIDATION**: When prompted, always verify documentation accuracy against implementation

#### Code Review Requirements

- Code reviewers should verify that new features include appropriate documentation requests
- Missing documentation should trigger suggestions for documentation updates
- Documentation changes should be reviewed for accuracy and completeness

#### Exceptions

- ✅ **EMERGENCY**: Critical security or bug fix documentation may be updated immediately
- ✅ **INLINE**: Code comments and JSDoc can be added during development
- ✅ **SUGGESTION**: Recommendations for documentation improvements are always allowed

---

## Rule 7 — Testing Requirements

All critical logic MUST have automated tests.

### Why this rule exists

- Prevents regressions and catches bugs early.
- Provides confidence when refactoring code.
- Serves as living documentation of expected behavior.
- Enables safe continuous integration and deployment.

### How to apply

#### Test Coverage

- ✅ **REQUIRED**: Write unit tests for all services, guards, interceptors, and pipes.
- ✅ **REQUIRED**: Write E2E tests for all API endpoints.
- ✅ **TARGET**: Maintain minimum 80% code coverage.
- ✅ **FOCUS**: Prioritize testing critical business logic and edge cases.

#### Test Quality

- ✅ **REQUIRED**: Write tests in English with descriptive test case names.
- ✅ **REQUIRED**: Use AAA pattern (Arrange, Act, Assert).
- ✅ **REQUIRED**: Tests should be independent and repeatable.
- ❌ **AVOID**: Tests that depend on external services (use mocks).

#### Test Execution

- ✅ **REQUIRED**: Run tests before committing: `pnpm test`
- ✅ **REQUIRED**: All tests must pass before merging.
- ✅ **AUTOMATED**: CI/CD runs tests on every push and PR.

### Enforcement and exceptions

- PRs with failing tests will be automatically rejected.
- New features without tests should not be approved.
- ✅ **EXCEPTIONS**: Prototype/experimental branches (must be documented).

---

## Rule 8 — Version Control and Commit Standards

All commits MUST follow Conventional Commits specification and project branching strategy.

### Why this rule exists

- Enables automated versioning and changelog generation via Semantic Release.
- Provides clear, searchable commit history.
- Facilitates code review and debugging.
- Ensures consistent collaboration practices.

### How to apply

#### Commit Messages

- ✅ **REQUIRED**: Follow Conventional Commits format: `type(scope): subject`
- ✅ **REQUIRED**: Use Commitizen for interactive commit creation: `pnpm run commit`
- ✅ **AUTOMATED**: Commitlint validates commit messages on commit.
- ✅ **REFERENCE**: See `.github/instructions/commit.instructions.md` for full details.

#### Commit Practices

- ✅ **REQUIRED**: Commit often with clear and descriptive messages.
- ✅ **REQUIRED**: Keep commits small, isolated, and logically grouped.
- ✅ **REQUIRED**: One logical change per commit.
- ❌ **NEVER**: Mix unrelated changes in the same commit.

#### Branching Strategy

- ✅ **REQUIRED**: Follow Gitflow or trunk-based development strategy.
- ✅ **MAIN BRANCH**: `main` - production-ready code only.
- ✅ **DEVELOP BRANCH**: `develop` - integration branch for features.
- ✅ **FEATURE BRANCHES**: `feature/<name>` - new features.
- ✅ **BUGFIX BRANCHES**: `bugfix/<name>` - bug fixes.
- ✅ **HOTFIX BRANCHES**: `hotfix/<name>` - urgent production fixes.

### Enforcement and exceptions

- Commitlint rejects improperly formatted commits.
- PRs with bad commit history should be squashed or rebased.

---

## Rule 9 — Security and Reliability

All code MUST follow security best practices and handle errors properly.

### Why this rule exists

- Protects sensitive data and prevents security vulnerabilities.
- Ensures application reliability and stability.
- Builds trust with users and stakeholders.
- Complies with industry standards and regulations.

### How to apply

#### Security Practices

- ❌ **NEVER**: Commit secrets, credentials, API keys, or sensitive data.
- ✅ **REQUIRED**: Use environment variables for configuration (`.env` files).
- ✅ **REQUIRED**: Add `.env` to `.gitignore`.
- ✅ **REQUIRED**: Validate and sanitize all external inputs (APIs, user input, files).
- ✅ **REQUIRED**: Use parameterized queries to prevent SQL injection.
- ✅ **REQUIRED**: Implement proper authentication and authorization.
- ✅ **REQUIRED**: Keep dependencies up-to-date and review for vulnerabilities: `pnpm audit`

#### Error Handling

- ✅ **REQUIRED**: Always validate inputs and handle edge cases.
- ✅ **REQUIRED**: Use try-catch blocks for error-prone operations.
- ✅ **REQUIRED**: Use NestJS exception filters for consistent error responses.
- ✅ **REQUIRED**: Log errors appropriately (use Logger service).
- ❌ **NEVER**: Expose stack traces or sensitive information in error responses.

#### Defensive Programming

- ✅ **REQUIRED**: Use defensive programming techniques to avoid unexpected crashes.
- ✅ **REQUIRED**: Write code with scalability and maintainability in mind.
- ❌ **AVOID**: Quick fixes that introduce technical debt.

### Enforcement and exceptions

- Code reviews should verify security best practices.
- CI/CD should include security scanning tools.
- Dependencies with known vulnerabilities should block builds.

---

## Rule 10 — Performance and Scalability

Code MUST be written with performance and scalability considerations.

### Why this rule exists

- Ensures the application can handle growth and increased load.
- Provides a good user experience with fast response times.
- Reduces infrastructure costs by optimizing resource usage.

### How to apply

#### Performance Best Practices

- ✅ **REQUIRED**: Avoid premature optimization; focus on correctness and clarity first.
- ✅ **REQUIRED**: When performance is necessary, measure and profile before optimizing.
- ✅ **REQUIRED**: Use caching where appropriate (Redis, in-memory cache).
- ✅ **REQUIRED**: Optimize database queries (use indexes, limit results).
- ❌ **AVOID**: N+1 query problems (use joins or eager loading).
- ❌ **AVOID**: Blocking operations in critical paths (use async/await).

#### Scalability Design

- ✅ **REQUIRED**: Design with scalability in mind from the start.
- ✅ **REQUIRED**: Use stateless services for horizontal scaling.
- ✅ **REQUIRED**: Implement rate limiting and throttling for public APIs.
- ✅ **REQUIRED**: Use pagination for large data sets.

### Enforcement and exceptions

- Performance tests should be part of the CI/CD pipeline.
- Code reviews should identify performance bottlenecks.

---

## Rule 11 — Consistency and Standardization

All code MUST follow consistent conventions and use automated tooling.

### Why this rule exists

- Reduces cognitive overhead when reading code.
- Facilitates team collaboration and code reviews.
- Prevents style debates and bikeshedding.
- Enables automation and tooling integration.

### How to apply

#### Automated Tooling

- ✅ **REQUIRED**: Use ESLint for code quality: `pnpm run lint`
- ✅ **REQUIRED**: Use Prettier for formatting: `pnpm run format`
- ✅ **AUTOMATED**: Husky + lint-staged enforce quality on commit.
- ✅ **REQUIRED**: Fix all linting errors before committing.

#### Configuration Management

- ✅ **REQUIRED**: Centralize configuration in `.env` files.
- ✅ **REQUIRED**: Use `@nestjs/config` module for configuration management.
- ❌ **NEVER**: Hard-code configuration values in source code.

#### Convention Adherence

- ✅ **REQUIRED**: Apply the same conventions across the entire codebase.
- ✅ **REQUIRED**: Follow NestJS best practices and architectural patterns.
- ✅ **REQUIRED**: Use dependency injection instead of direct instantiation.

### Enforcement and exceptions

- Automated tools block commits with linting or formatting errors.
- Code reviews enforce consistency.

---

## Rule 12 — Continuous Improvement

The codebase MUST be continuously improved and maintained.

### Why this rule exists

- Prevents technical debt accumulation.
- Keeps the codebase modern and maintainable.
- Improves team productivity and code quality over time.
- Adapts to changing requirements and technologies.

### How to apply

#### Refactoring

- ✅ **REQUIRED**: Refactor when necessary to improve code quality.
- ✅ **REQUIRED**: Always question whether the current solution is the most maintainable.
- ❌ **AVOID**: Unnecessary refactoring that doesn't add value.
- ✅ **REQUIRED**: Include tests when refactoring to prevent regressions.

#### Learning and Adaptation

- ✅ **REQUIRED**: Learn from mistakes and update practices accordingly.
- ✅ **REQUIRED**: Document lessons learned in project knowledge base.
- ✅ **REQUIRED**: Keep up-to-date with NestJS updates and best practices.
- ✅ **REQUIRED**: Review and update dependencies regularly.

#### Code Reviews

- ✅ **REQUIRED**: Review and refactor code regularly to maintain quality.
- ✅ **REQUIRED**: Provide constructive feedback in code reviews.
- ✅ **REQUIRED**: Address code review comments before merging.

### Enforcement and exceptions

- Regular code quality audits should be scheduled.
- Technical debt should be tracked and prioritized.

---

## Rule 13 — Documentation Organization and Centralization

All project documentation MUST be organized centrally with a clear hierarchy and consistent structure to maintain information integrity and accessibility. Documentation MUST evolve organically by updating existing files rather than creating specific implementation reports or scattered topic files.

### Why this rule exists

- **Prevents Documentation Fragmentation**: Avoids duplication and scattered documentation across the project.
- **Single Source of Truth**: Ensures one authoritative location for each topic or concept.
- **Maintains Consistency**: Uniform documentation structure and format throughout the project.
- **Improves Discoverability**: Clear navigation and organization of project documentation.
- **Reduces Maintenance Overhead**: Prevents accumulation of redundant and obsolete documentation files.
- **Long-term Sustainability**: Grows documentation as a cohesive knowledge base rather than random file collection.
- **Prevents Documentation Debt**: Avoids the creation of unnecessary files that become maintenance burden over time.

### How to apply

#### Documentation Evolution Strategy

- ✅ **UPDATE FIRST**: Always search for existing documentation covering the topic before creating new files
- ✅ **CONSOLIDATE**: Merge related content into existing comprehensive documents
- ✅ **EXPAND EXISTING**: Add new sections to established documents rather than creating separate files
- ❌ **NEVER**: Create implementation-specific reports or temporary documentation files
- ❌ **NEVER**: Create multiple files covering the same conceptual area
- ✅ **STRATEGIC CREATION**: Only create new files for genuinely new topics or major architectural areas

#### Documentation Hierarchy

- ✅ **REQUIRED**: Use `README.md` as the **main project guide** and entry point
- ✅ **REQUIRED**: Place all detailed documentation in the `docs/` directory
- ✅ **REQUIRED**: Organize `docs/` with clear subdirectories by topic or function
- ❌ **NEVER**: Create multiple README files throughout the project
- ❌ **NEVER**: Create `.md` files outside the `docs/` directory (except root `README.md`)
- ❌ **NEVER**: Create topic-specific implementation reports (e.g., `feature-x-implementation-report.md`)

#### Sustainable Documentation Practices

- ✅ **ORGANIC GROWTH**: Let documentation evolve naturally by expanding existing content
- ✅ **TOPIC CONSOLIDATION**: Group related information under unified topic files
- ✅ **VERSION EVOLUTION**: Update documentation sections to reflect current implementation state
- ✅ **CROSS-REFERENCING**: Link between related sections in different documents
- ❌ **AVOID**: Creating separate files for each feature, bug fix, or implementation detail
- ❌ **AVOID**: Temporary documentation that becomes stale over time

#### Main README Structure

- ✅ **REQUIRED**: Keep `README.md` as a comprehensive **project overview** with:
  - Project description and key features
  - Quick start and setup instructions
  - Main commands and usage examples
  - Links to detailed documentation in `docs/`
  - Architecture overview and technology stack
  - Contributing guidelines and project structure

#### Detailed Documentation in `docs/`

- ✅ **REQUIRED**: Create focused documentation in `docs/` for:
  - **API documentation**: `docs/api/` or `docs/endpoints/`
  - **Architecture details**: `docs/architecture/` or `docs/technical/`
  - **Development guides**: `docs/development/` or `docs/guides/`
  - **Configuration**: `docs/configuration/` or `docs/setup/`
  - **Testing**: `docs/testing/` or `docs/quality/`
  - **Deployment**: `docs/deployment/` or `docs/operations/`

#### Documentation Maintenance

- ✅ **REQUIRED**: Always **update existing documentation** rather than creating new files
- ✅ **REQUIRED**: Use cross-references and links between documentation files
- ✅ **REQUIRED**: Maintain a documentation index in `docs/README.md` or similar
- ✅ **REQUIRED**: Review and update documentation with every significant change
- ✅ **ANTI-PATTERN**: Resist the urge to create "quick" documentation files that bypass the main structure
- ✅ **CONSOLIDATION**: Regularly review and merge redundant or overlapping documentation

#### Long-term Documentation Health

- ✅ **AUDIT REGULARLY**: Periodically review documentation structure for redundancy and gaps
- ✅ **RETIRE OBSOLETE**: Remove or merge outdated documentation files
- ✅ **MAINTAIN RELEVANCE**: Keep documentation current with actual implementation
- ✅ **STRATEGIC EXPANSION**: Plan documentation growth to serve long-term project needs
- ❌ **AVOID**: Accumulation of temporary, implementation-specific, or one-off documentation files

### Examples

#### ✅ Correct Documentation Structure

```
PROJECT-ROOT/
├── README.md                    # Main project guide
├── docs/
│   ├── README.md               # Documentation index
│   ├── api/
│   │   ├── authentication.md
│   │   ├── endpoints.md
│   │   └── schemas.md
│   ├── development/
│   │   ├── setup.md
│   │   ├── testing.md
│   │   └── debugging.md
│   ├── architecture/
│   │   ├── overview.md
│   │   ├── database.md
│   │   └── security.md
│   └── deployment/
│       ├── production.md
│       └── ci-cd.md
└── src/
    └── (source code only)
```

#### ❌ Incorrect Documentation Structure

```
PROJECT-ROOT/
├── README.md
├── API-README.md               ❌ Multiple READMEs
├── SETUP.md                    ❌ Outside docs/
├── src/
│   ├── auth/
│   │   └── AUTH-GUIDE.md       ❌ Documentation in source
│   └── users/
│       └── README.md           ❌ Multiple READMEs
├── config/
│   └── CONFIG-DOCS.md          ❌ Outside docs/
└── deployment-guide.md         ❌ Outside docs/
```

### Content Guidelines

#### Main README.md

- ✅ **INCLUDE**: Project overview, quick start, main features, key commands
- ✅ **INCLUDE**: Links to detailed documentation: `See [API Documentation](docs/api/README.md)`
- ✅ **LIMIT**: Keep concise but comprehensive (aim for 200-500 lines)
- ✅ **UPDATE**: Regularly update to reflect current project state

#### Documentation in docs/

- ✅ **DETAILED**: In-depth technical information, tutorials, guides
- ✅ **SPECIFIC**: Topic-focused content (one topic per file)
- ✅ **EXAMPLES**: Code samples, configuration examples, use cases
- ✅ **NAVIGATION**: Clear headings, table of contents, cross-references

### Enforcement and exceptions

- ✅ **REQUIRED**: All new documentation must follow this structure
- ❌ **NEVER**: Create documentation files outside the approved structure
- ❌ **NEVER**: Create implementation-specific reports or temporary documentation files
- ✅ **REFACTOR**: Existing scattered documentation must be consolidated into `docs/`
- ✅ **EXCEPTIONS**: License, Contributing guidelines, and Changelog may remain in root if preferred

### Code review and CI

- Code reviewers must verify that new documentation follows the centralized structure
- PRs that create documentation outside `docs/` should be rejected
- Automated checks should validate documentation structure compliance
- **CRITICAL**: PRs that create implementation reports or duplicate topic files should be rejected

### Migration of existing documentation

When implementing this rule in existing projects:

1. **Audit**: Identify all existing `.md` files throughout the project
2. **Consolidate**: Move detailed documentation to appropriate `docs/` subdirectories
3. **Update**: Revise `README.md` to be the main guide with links to `docs/`
4. **Link**: Update all internal references to point to new locations
5. **Clean**: Remove redundant or outdated documentation files

---

## Rule 14 — Controlled Commit Operations

All commit operations MUST be performed by developers manually or through explicit commit prompt triggers. AI agents and automation tools are restricted from executing commits directly to maintain developer control and accountability.

### Why this rule exists

- **Developer Accountability**: Ensures commits are intentional and reviewed by humans
- **Quality Control**: Prevents automated commits that may contain errors or unintended changes
- **Audit Trail**: Maintains clear responsibility for all code changes
- **Security**: Prevents unauthorized code commits through AI automation
- **Review Process**: Ensures all changes go through proper human review
- **Version Control Integrity**: Maintains clean, intentional commit history

### How to apply

#### Commit Restrictions

- ❌ **NEVER**: Execute `git commit` commands automatically
- ❌ **NEVER**: Perform commits during regular chat interactions
- ❌ **NEVER**: Commit changes without explicit developer authorization
- ✅ **ALLOWED**: Suggest commit messages using commit prompt system
- ✅ **ALLOWED**: Recommend when commits should be made
- ✅ **REQUIRED**: Use commit prompt for commit message generation only

#### Commit Message Assistance

- ✅ **REQUIRED**: When asked for commit help, use the commit prompt system
- ✅ **REQUIRED**: Generate commit messages following Conventional Commits specification
- ✅ **REQUIRED**: Provide commit message suggestions based on changes made
- ✅ **REQUIRED**: Include appropriate scope and type information
- ❌ **NEVER**: Execute the actual commit operation

#### Developer Responsibilities

- ✅ **REQUIRED**: Developers must manually execute all commits
- ✅ **REQUIRED**: Developers must review and validate suggested commit messages
- ✅ **REQUIRED**: Use `pnpm run commit` for interactive commit creation
- ✅ **REQUIRED**: Ensure all pre-commit hooks and validations pass

### Enforcement and exceptions

#### Strict Enforcement

- ✅ **REQUIRED**: All commits must be human-initiated and executed
- ❌ **NEVER**: Automate commit operations through AI or scripts
- ✅ **VALIDATION**: Pre-commit hooks validate commit message format
- ✅ **REVIEW**: All commits subject to code review process

#### Commit Suggestion Process

1. **Analyze Changes**: Review modified files and changes made
2. **Generate Message**: Create appropriate commit message following conventions
3. **Provide Suggestion**: Offer commit message to developer
4. **Manual Execution**: Developer reviews and executes commit manually

#### Exceptions

- ✅ **EMERGENCY**: Critical hotfixes may require expedited but still manual commits
- ✅ **AUTOMATION**: CI/CD systems may perform automated commits for releases (with proper configuration)
- ❌ **NO EXCEPTIONS**: AI agents must never perform direct commits

### Integration with Existing Rules

This rule works in conjunction with:

- **Rule 2**: Error correction must be validated before suggesting commits
- **Rule 3**: Formatting must be applied before commit suggestions
- **Rule 8**: Commit messages must follow Conventional Commits specification
- **Rule 6**: Documentation changes require explicit prompts, not automatic commits

### Best Practices

- Always suggest running `pnpm run commit` for interactive commit creation
- Provide clear, descriptive commit messages following project conventions
- Recommend appropriate commit scope and type based on changes
- Suggest when changes should be committed together or separately
- Encourage frequent, small commits with clear purposes

---

## Rule 15 — Controlled Migration Management in Feature Branches

All database migrations in feature branches MUST follow strict control procedures to prevent migration conflicts and maintain database schema consistency. Each feature branch is limited to one migration file, which must include the branch name and be managed exclusively through terminal commands.

### Why this rule exists

- **Prevents Migration Conflicts**: Avoids conflicts when multiple feature branches modify database schema simultaneously
- **Ensures Schema Consistency**: Maintains predictable database migration order and prevents schema drift
- **Branch Isolation**: Each feature branch maintains its own isolated migration that can be safely merged
- **Naming Convention**: Migration names include branch information for better traceability and debugging
- **Terminal-Only Operations**: Ensures consistent migration generation and prevents manual file creation errors
- **Rollback Safety**: Protects migrations from other branches while allowing safe cleanup within the current branch

### How to apply

#### Migration Limitations per Branch

- ✅ **REQUIRED**: Each feature branch can have **ONLY ONE** migration file
- ✅ **REQUIRED**: Migration name must include the current branch name for identification
- ❌ **NEVER**: Create multiple migrations in the same feature branch
- ❌ **NEVER**: Create migration files manually or through copy/paste operations
- ✅ **REQUIRED**: Use terminal commands exclusively for all migration operations

#### Migration Creation Process

1. **Check Existing Migrations**: Verify if the current branch already has a migration
2. **Delete if Exists**: If a migration exists in the current branch, delete it first
3. **Generate New Migration**: Always create a fresh migration using Prisma CLI
4. **Naming Convention**: Include branch name in the migration description

#### Terminal Commands Only

- ✅ **REQUIRED**: Use `pnpm db:migrate` for migration generation
- ✅ **REQUIRED**: Use `pnpm db:reset` or `prisma migrate reset` for cleanup if needed
- ❌ **NEVER**: Create, edit, or delete migration files manually
- ❌ **NEVER**: Copy migration files from other branches
- ✅ **REQUIRED**: Let Prisma CLI handle all migration file operations

#### Branch-Based Migration Management

```bash
# Check current branch
git branch --show-current

# Example: feature/user-authentication
# Migration should be named: "add-user-auth-feature-user-authentication"

# If migration exists in current branch, reset and regenerate
pnpm db:reset
pnpm db:migrate

# Or delete specific migration from current branch only
# (Never delete migrations from other branches)
```

#### Migration Naming Convention

- ✅ **REQUIRED**: Include branch name in migration description
- ✅ **PATTERN**: `[feature-description]-[branch-name]`
- ✅ **EXAMPLES**:
  - Branch: `feature/user-auth` → Migration: `add-user-authentication-feature-user-auth`
  - Branch: `feature/payment-system` → Migration: `implement-payment-tables-feature-payment-system`
  - Branch: `bugfix/user-email-unique` → Migration: `fix-user-email-constraint-bugfix-user-email-unique`

### How to apply (Step-by-step)

#### Before Creating a Migration

1. **Check Current Branch**:

   ```bash
   git branch --show-current
   ```

2. **Check Existing Migrations in Branch**:

   ```bash
   # Look for migrations with current branch name
   ls prisma/migrations/ | grep "$(git branch --show-current | sed 's/[^a-zA-Z0-9]/-/g')"
   ```

3. **If Migration Exists, Delete and Recreate**:
   ```bash
   # Reset database and regenerate migration
   pnpm db:reset
   ```

#### Creating a New Migration

1. **Make Schema Changes**: Edit `prisma/schema.prisma`

2. **Generate Migration with Branch Name**:

   ```bash
   # Get current branch for naming
   BRANCH_NAME=$(git branch --show-current | sed 's/[^a-zA-Z0-9]/-/g')

   # Generate migration with descriptive name including branch
   pnpm db:migrate --name "add-user-authentication-${BRANCH_NAME}"
   ```

3. **Verify Migration Created**:
   ```bash
   ls -la prisma/migrations/
   ```

#### Branch Protection Rules

- ✅ **CURRENT BRANCH ONLY**: Only modify/delete migrations created in the current branch
- ❌ **NEVER**: Delete or modify migrations from other branches (main, develop, other features)
- ✅ **SAFE CLEANUP**: Use `pnpm db:reset` to safely regenerate current branch migration
- ✅ **BRANCH ISOLATION**: Each branch maintains its own migration namespace

### Workflow Examples

#### Example 1: New Feature Branch

```bash
# 1. Create feature branch
git checkout -b feature/user-profiles

# 2. Make schema changes
# Edit prisma/schema.prisma

# 3. Generate migration
pnpm db:migrate --name "add-user-profiles-feature-user-profiles"

# 4. Verify
ls prisma/migrations/ | grep "user-profiles-feature-user-profiles"
```

#### Example 2: Modify Existing Feature Migration

```bash
# 1. Check current branch
git branch --show-current  # feature/user-profiles

# 2. Need to modify schema - reset and regenerate
pnpm db:reset

# 3. Make new schema changes
# Edit prisma/schema.prisma

# 4. Generate fresh migration
pnpm db:migrate --name "add-user-profiles-feature-user-profiles"
```

#### Example 3: Branch with Existing Migration

```bash
# 1. Switch to existing feature branch
git checkout feature/payment-system

# 2. Check for existing migration
ls prisma/migrations/ | grep "payment-system"

# 3. If migration exists and needs changes
pnpm db:reset  # This will recreate database and prompt for new migration

# 4. Apply schema changes and generate new migration
pnpm db:migrate --name "implement-payment-tables-feature-payment-system"
```

### Validation and Enforcement

#### Pre-commit Validation

- ✅ **CHECK**: Verify only one migration exists per feature branch
- ✅ **NAMING**: Ensure migration name includes branch identifier
- ✅ **TERMINAL**: Confirm migration was generated via Prisma CLI (not manually created)

#### Code Review Requirements

- ✅ **REVIEW**: Check that migration follows naming convention
- ✅ **VERIFY**: Ensure migration is the only one for the feature branch
- ✅ **VALIDATE**: Confirm migration was generated properly via terminal

#### Automated Checks

```bash
# Example validation script
CURRENT_BRANCH=$(git branch --show-current)
BRANCH_MIGRATIONS=$(ls prisma/migrations/ | grep "${CURRENT_BRANCH}" | wc -l)

if [ "$BRANCH_MIGRATIONS" -gt 1 ]; then
  echo "❌ Error: Multiple migrations found for branch ${CURRENT_BRANCH}"
  exit 1
fi
```

### Common Scenarios

#### Merging Feature Branches

1. **Before Merge**: Ensure migration name follows convention
2. **Conflict Resolution**: If migration conflicts occur, regenerate migration in feature branch
3. **Post-Merge**: Migration becomes part of main branch history

#### Long-Running Feature Branches

1. **Periodic Sync**: Regularly sync with main branch
2. **Migration Conflicts**: If conflicts arise, regenerate migration in feature branch
3. **Schema Updates**: Always regenerate migration rather than manually editing

### Enforcement and exceptions

#### Strict Enforcement

- ✅ **REQUIRED**: All migrations must be generated via terminal commands
- ✅ **REQUIRED**: Each feature branch limited to one migration
- ✅ **REQUIRED**: Migration names must include branch identifier
- ❌ **NEVER**: Create, edit, or copy migration files manually
- ❌ **NEVER**: Delete migrations from other branches

#### Exceptions

- ✅ **EMERGENCY**: Critical production hotfixes may require immediate migration (with proper review)
- ✅ **MAIN BRANCH**: Main branch migrations follow standard Prisma practices
- ❌ **NO EXCEPTIONS**: Feature branches must always follow this rule

#### Error Recovery

If migration rules are violated:

1. **Reset Migration**: `pnpm db:reset` to clean slate
2. **Regenerate**: Create proper migration following conventions
3. **Document**: Record the issue and resolution in commit message

### Integration with Existing Rules

This rule works in conjunction with:

- **Rule 1**: Use proper tools (Prisma CLI) for migration generation
- **Rule 2**: Validate migration correctness before proceeding
- **Rule 8**: Include migration changes in appropriate commit messages
- **Rule 14**: Commit migration changes manually with proper review

### Best Practices

- Always run `pnpm db:migrate` from repository root
- Include meaningful descriptions that explain the schema change
- Test migration in development environment before committing
- Document breaking changes in migration commit messages
- Coordinate with team when working on overlapping schema changes

---

## Summary

These rules are **mandatory** and apply to all contributors, including AI coding agents, automation tools, and human developers. Violations should be addressed immediately in code reviews and blocked by automated tooling where possible.

### Critical Control Rules

- **Rule 6**: Documentation generation is controlled through specific prompts (`wiki`, `readme`)
- **Rule 14**: Commit operations must be performed manually by developers
- **Rule 15**: Database migrations in feature branches must follow strict control procedures
- **Rule 4**: All files must use technical English
- **Rule 13**: Documentation must follow centralized organization

### Quality and Consistency Rules

- **Rule 1**: Use Nest CLI for all generated files
- **Rule 2**: Validate all error corrections before reporting
- **Rule 3**: Apply formatting before all commits
- **Rule 5-12**: Maintain code quality, testing, security, and best practices

### Database and Migration Rules

- **Rule 15**: Each feature branch limited to one migration with branch-specific naming
- **Rule 1**: Use Prisma CLI exclusively for migration operations
- **Rule 14**: Migration changes must be committed manually with proper review

### AI Agent Restrictions

- ❌ **Cannot commit code** without explicit developer action
- ❌ **Cannot modify documentation** without prompt triggers
- ❌ **Cannot create files** outside approved processes
- ❌ **Cannot create or modify migrations** manually
- ✅ **Can suggest** improvements and provide guidance
- ✅ **Can generate** commit messages and documentation when prompted
- ✅ **Can recommend** migration operations via terminal commands

**Remember**: These rules exist to maintain code quality, consistency, and maintainability while ensuring developer control over critical operations. Following them ensures a healthy, scalable, and reliable codebase with proper accountability. 🎯
